# Unsupervised Learning

```{r, echo = FALSE, message = FALSE}
source(here::here("scripts/setup.R"))
```
<br>
<br>

## Splitting of Dataset

<br>

In order to have a clearer view on the data, we decided to split the main dataset to two datasets; one for Home teams and another for Away teams. The goal is to study the performance of each team when they are both away or home. 


```{r, echo=FALSE, warning=FALSE}
setwd(here::here("Data_New/"))
premier_league_results <- read_csv("premier_league_results_clean.csv")
```

```{r, echo=FALSE}
# Divide the dataset into Home and Away

PLR_Home <- premier_league_results %>% select(home_team, full_time_home_goals, half_time_home_goals, home_shots, home_shots_ontarget, home_fouls, home_corners, home_yellow_cards, home_red_cards)

PLR_Away <- premier_league_results %>% select (away_team, full_time_away_goals, half_time_away_goals, away_shots, away_shots_ontarget, away_fouls, away_corners, away_yellow_cards, away_red_cards)

head(PLR_Home) %>% kable(caption = "**Premiere League Results for Home Teams**") %>%
  kable_styling(bootstrap_options = c("striped","hover","condensed"),
                fixed_thead = T) %>% kable_paper() %>%  scroll_box(width = "100%", height = "300px")
```
<br>
```{r, echo=FALSE}
head(PLR_Away) %>% kable(caption = "**Premiere League Results for Away Teams**") %>%
  kable_styling(bootstrap_options = c("striped","hover","condensed"),
                fixed_thead = T) %>% kable_paper() %>%  scroll_box(width = "100%", height = "300px")
```

<br>

We have also grouped by the teams in order to have an overview of the variables for each team. We calculated the meadian of each variable to obtain a robust grouping. 
```{r}
# Group by teams

PLR_Home <- PLR_Home %>% group_by(home_team) %>% 
  summarise(Full_time_home_goals = median(full_time_home_goals), 
            Half_time_home_goals = median(half_time_home_goals), 
            Home_shots = median(home_shots),
            Home_shots_ontarget = median(home_shots_ontarget),
            Home_fouls = median(home_fouls),
            Home_corners = median(home_corners),
            Home_yellow_cards = median(home_yellow_cards),
            Home_red_cards = mean(home_red_cards), .groups = 'drop')


PLR_Away <- PLR_Away %>% group_by(away_team) %>% 
  summarise(Full_time_away_goals = median(full_time_away_goals), 
            Half_time_away_goals = median(half_time_away_goals), 
            Away_shots = median(away_shots),
            Away_shots_ontarget = median(away_shots_ontarget),
            Away_fouls = median(away_fouls),
            Away_corners = median(away_corners),
            Away_yellow_cards = median(away_yellow_cards),
            Away_red_cards = mean(away_red_cards), .groups = 'drop')
```
<br>

After calculating the median, our dataset looks like this:
<br>

```{r, echo=FALSE}
head(PLR_Home)%>% kable(caption = "**Median Premiere League Results for Home Teams**") %>%
  kable_styling(bootstrap_options = c("striped","hover","condensed"),
                fixed_thead = T) %>% kable_paper() %>%  scroll_box(width = "100%", height = "300px")
```

<br>

```{r, echo=FALSE}
head(PLR_Away)%>% kable(caption = "**Median Premiere League Results for Away Teams**") %>%
  kable_styling(bootstrap_options = c("striped","hover","condensed"),
                fixed_thead = T) %>% kable_paper() %>%  scroll_box(width = "100%", height = "300px")
```

<br>
<br>

## Scaling the Data

<br>

Our dataset contains various variables, each of which has its own scale. As we can see below, the "Home_shots" variable has a scale ranging from around 10 to 18, while "Full_time_home_goals" has a scale ranging from around 0 to 3. Therefore, we will need to scale the data in order to give the same weight for all variables. 
```{r, echo=FALSE}

# Scale features for home and away

PLR_Home_Scale <- data.frame(scale(PLR_Home[,-1], center=FALSE)) # %>% as_data_frame()
PLR_Away_Scale <- data.frame(scale(PLR_Away[,-1], center=FALSE)) # %>% as_data_frame()


PLR_Home_Scale <- PLR_Home_Scale %>% 
  mutate(home_team = PLR_Home$home_team, .before = Full_time_home_goals )

PLR_Away_Scale <- PLR_Away_Scale %>% 
  mutate(away_team = PLR_Away$away_team, .before = Full_time_away_goals )

```
<br>

The following two tables show the scaled datasets for the first 6 teams. 

<br>

```{r, echo=FALSE}
head(PLR_Home_Scale)%>% kable(caption = "**Scaled Premiere League Results for Home Teams**") %>%
  kable_styling(bootstrap_options = c("striped","hover","condensed"),
                fixed_thead = T) %>% kable_paper() %>%  scroll_box(width = "100%", height = "300px")
```

<br>

```{r, echo=FALSE}
head(PLR_Away_Scale)%>% kable(caption = "**Scaled Premiere League Results for Away Teams**") %>%
  kable_styling(bootstrap_options = c("striped","hover","condensed"),
                fixed_thead = T) %>% kable_paper() %>%  scroll_box(width = "100%", height = "300px")
```
<br>
<br>

## Principal Component Analysis (PCA)

**_Results of Variables_**

For our unsupervised learning, we decided to work on PCA in order to see the clusters formed and study the important components of each of the Home and Away teams. 

<br>

The below shows the results of the PCA for the teams when Home 


```{r, echo=FALSE}
rownames(PLR_Home_Scale)[1] <- "Arsenal"
rownames(PLR_Home_Scale)[2] <- "Bournemouth"
rownames(PLR_Home_Scale)[3] <- "Burnley"
rownames(PLR_Home_Scale)[4] <- "Chelsea"
rownames(PLR_Home_Scale)[5] <- "Crystal Palace"
rownames(PLR_Home_Scale)[6] <- "Everton"
rownames(PLR_Home_Scale)[7] <- "Leicester"
rownames(PLR_Home_Scale)[8] <- "Liverpool"
rownames(PLR_Home_Scale)[9] <- "Man City"
rownames(PLR_Home_Scale)[10] <- "Man United"
rownames(PLR_Home_Scale)[11] <- "Southampton"
rownames(PLR_Home_Scale)[12] <- "Tottenham"
rownames(PLR_Home_Scale)[13] <- "Watford"
rownames(PLR_Home_Scale)[14] <- "West Ham"

rownames(PLR_Away_Scale)[1] <- "Arsenal"
rownames(PLR_Away_Scale)[2] <- "Bournemouth"
rownames(PLR_Away_Scale)[3] <- "Burnley"
rownames(PLR_Away_Scale)[4] <- "Chelsea"
rownames(PLR_Away_Scale)[5] <- "Crystal Palace"
rownames(PLR_Away_Scale)[6] <- "Everton"
rownames(PLR_Away_Scale)[7] <- "Leicester"
rownames(PLR_Away_Scale)[8] <- "Liverpool"
rownames(PLR_Away_Scale)[9] <- "Man City"
rownames(PLR_Away_Scale)[10] <- "Man United"
rownames(PLR_Away_Scale)[11] <- "Southampton"
rownames(PLR_Away_Scale)[12] <- "Tottenham"
rownames(PLR_Away_Scale)[13] <- "Watford"
rownames(PLR_Away_Scale)[14] <- "West Ham"
```


```{r, echo=FALSE}
#PLR_Home_numeric <- PLR_Home_Scale %>% select(where(is.numeric))
#PLR_Away_numeric <- PLR_Away_Scale %>% select(where(is.numeric)) 

PLR_Home_pca <- PCA(PLR_Home_Scale [,-1], ncp = 11, graph = FALSE)
PLR_Away_pca <- PCA(PLR_Away_Scale [,-1], ncp = 11, graph = FALSE)


PLR_Home_pca

#PCAmix(X.quanti = NULL, X.quali = NULL, ndim = 5, rename.level = FALSE, weight.col.quanti = NULL, weight.col.quali = NULL, graph = TRUE)
```

The below shows the results of the PCA for the teams when Away
```{r, echo=FALSE}
PLR_Away_pca
```

<br>
<br>

**_Graphing of Variables_**

The below two graphs show the same eight (8) variables and for all of the teams when they are both Home and Away. Dimension 1 explains 54.3% of the variance of the data and Dimension 2 explains 21.4% making a total of 75.7% of the variance explained by these two components.  
Both graphs make sense since they show that all variables related to "goals" and "shots" are correlated to Dimension 2 and variables related to "cards" are correlated with Dimension 1. Therefore, we can deduce that Dimension 1 relates to Goals and Dimension 2 related to Cards.                      

```{r, echo=FALSE}

# fviz_pca_var(PLR_Home_pca, repel = TRUE, title = "Variable PCA for Home Teams")
# fviz_pca_var(PLR_Away_pca, repel = TRUE, title = "Variable PCA for Away Teams")

grid.arrange(fviz_pca_var(PLR_Home_pca, repel = TRUE, title = "Home Teams", col.var = "Blue"), fviz_pca_var(PLR_Away_pca, repel = TRUE, title = "Away Teams", col.var = "#2EDFC7"), ncol=2)
```
**_Contribution of Variables_**

To  better interpret these dimensions, we can extract the contributions of each features in the dimension. Below, for Dimension1. We can see below the graphs showing contributions of each variable in both Home and Away states. We can conclude that whether the teams are playing Home or Away, there isn't a huge change in the contribution of the variables. 

Further, as shown in the variable graphs, the variables _yello cards_, _red cards_, and _fouls_ are crrelated with Dimension 2. 

```{r, echo=FALSE}
# Extract the contributions of each features in the dimension.
fviz_contrib(PLR_Home_pca, choice = "var", axes = 1, title="Variable Contribution to Dim-1") + fviz_contrib(PLR_Away_pca, choice = "var", axes = 1, title="Variable Contribution to Dim-1", fill = "#2EDFC7")

fviz_contrib(PLR_Home_pca, choice = "var", axes = 2, title="Variable Contribution to Dim-2") + fviz_contrib(PLR_Away_pca, choice = "var", axes = 2, title="Variable Contribution to Dim-2", fill = "#2EDFC7")
```

```{r, echo=FALSE}
# fviz_pca_ind(PLR_Home_pca) ## only the individuals
# fviz_pca_ind(PLR_Away_pca)

# fviz_pca_biplot(PLR_Home_pca, repel = TRUE, col.var = "#2E9FDF", col.ind = "#696969", label = "all")
```

<br>
```{r, echo=FALSE}
# fviz_pca_biplot(PLR_Away_pca, repel = TRUE, col.var = "#2EDFC7", col.ind = "#696969", label = "all")
```
**_Dimension Analysis_**

The summaries below show percentage of contribution of each principle component and the total % eplained along with various details of each component and individual. The scree plots below show an easier and graphical representation of the same percentage of variance for all the Dimensions. As shown below, the first 3 dimensions explain more than 80% of the variance. 

<br>
<br>
Summary of Variables - Home: 
```{r, echo=FALSE}
Summary_Home <- summary(PLR_Home_pca)
Summary_Home
```
<br>
<br>
Summary of Variables - Away: 
```{r, echo=FALSE}
Summary_Away <- summary(PLR_Away_pca)

Summary_Away
```

<br>
<br>

```{r, echo=FALSE}
ScreeHome <- fviz_eig(PLR_Home_pca, addlabels = TRUE, ncp=11, title ="Home - Scree plot" )
ScreeAway <- fviz_eig(PLR_Away_pca, addlabels = TRUE, ncp=11, title ="Away - Scree plot" )

ScreeHome + ScreeAway

```

<br>
<br>
**_Biplots_**

Creating the biplots below, we can combine clustering and pca in order to see each individual, it's relationship with other individuals and variables and create clusters. Based on the screeplots above, to decrease the _within variance_ and increase the _between variance_ and keeping in mind the complexity of the model, we have created three clusters. 

```{r, echo=FALSE}
PLR_Home_hc2 <- hclust(dist(PLR_Home_Scale[,-1], method = "manhattan"), method = "complete")
PLR_Away_hc2 <- hclust(dist(PLR_Away_Scale[,-1], method = "manhattan"), method = "complete")

PLR_Home_clust <- cutree(PLR_Home_hc2, k = 3)
PLR_Away_clust <- cutree(PLR_Away_hc2, k = 3)

fviz_pca_biplot(PLR_Home_pca,
             col.ind = factor(PLR_Home_clust),  
             #addEllipses = TRUE, 
             #ellipse.type = "confidence",
             legend.title = "Clusters", 
             repel = TRUE)

fviz_pca_biplot(PLR_Away_pca,
             col.ind = factor(PLR_Away_clust),  
             #addEllipses = TRUE, 
             #ellipse.type = "confidence",
             legend.title = "Clusters", 
             repel = TRUE)
```
<br>
We can see that, for both graphs, the clusters represented are separated by the strength of correlation with each Dimension.
For example, for Home Teams, cluster 1 consists of _Man United_ and _Arsenal_; both of which have relatively a weak positive correlation to Dimension 2 and strong positive correlation to Dimension 1. The plot also shows the seed of that cluster denoted by a bigger circle in the middle of the cluster.  
For Away teams, _Man United_ and _Arsenal_ are also part of cluster one among other teams however falling in the other quadrant where they are negatively correlated with Dimension 2. 

<br>
<br>

## Clustering

<br>
<br>

For the clustering method, we calculated the Manhattan distance to form clusters of the Home and Away teams. 

<br>

Below are the dendograms created by complete linkage. 

```{r, echo=FALSE, warning=FALSE}
# matrix of Manhattan distances 
PLR_Home_Mdistance <- dist(PLR_Home_Scale[,], method = "manhattan")

PLR_Away_Mdistance <- dist(PLR_Away_Scale[,], method = "manhattan")
```

**Manhattan Distance - Home**
```{r, echo=FALSE, warning=FALSE}
PLR_Home_Mdistance 
```

**Manhattan Distance - Away**
```{r, echo=FALSE, warning=FALSE}
PLR_Away_Mdistance 
```

```{r, echo=FALSE, warning=FALSE}
#code to try to change the labels

# PLR_Home_hc <- hclust(PLR_Home_Mdistance, method = "complete")
# plot(PLR_Home_hc, hang=-1, labels_col(value = c("skyblue", "orange", "grey"), k=3), branches_color(value = c("skyblue", "orange", "grey"), k = 3) ) 
# 
# PLR_Away_hc <- hclust(PLR_Away_Mdistance, method = "complete")
# plot(PLR_Away_hc, hang=-1)



###HOME###

dend_home <- PLR_Home_Scale[,] %>% 
  dist("manhattan") %>% 
  hclust(method = "complete") %>% 
  as.dendrogram() 

#par(mar=c(1,1,1,7))
dend_home %>%
  set("labels_col", value = c("#5dc263", "#f86565", "#669af0"), k=3) %>%
  set("branches_k_color", value = c("#5dc263", "#f86565", "#669af0"), k = 3) %>%
  plot(horiz=TRUE, axes=FALSE, title="Home Dendrogram")
abline(v = 350, lty = 2)


###AWAY###

dend_away <- PLR_Away_Scale[,] %>% 
  dist("manhattan") %>% 
  hclust(method = "complete") %>% 
  as.dendrogram() 

#par(mar=c(1,1,1,7))
dend_away %>%
  set("labels_col", value = c("#5dc263", "#f86565", "#669af0"), k=3) %>%
  set("branches_k_color", value = c("#5dc263", "#f86565", "#669af0"), k = 3) %>%
  plot(horiz=TRUE, axes=FALSE, title="Away Dendrogram")
abline(v = 350, lty = 2)
```

```{r, echo=FALSE}
#We cut the tree to 4 clusters, and represent the result.
#We also extract the cluster assignment of each wine.
#
# plot(PLR_Home_hc, hang=-1)
# rect.hclust(PLR_Home_hc, k=4)
# PLR_Home_clust <- cutree(PLR_Home_hc, k=4)
# PLR_Home_clust
# 
# 
# fviz_nbclust(PLR_Home_Scale,
#              hcut, hc_method="complete",
#              hc_metric="manhattan",
#              method = "wss", 
#              k.max = 25, verbose = FALSE)
# fviz_nbclust(PLR_Home_Scale,
#              hcut, hc_method="complete",
#              hc_metric="manhattan",
#              method = "silhouette", 
#              k.max = 25, verbose = FALSE)
# fviz_nbclust(PLR_Home_Scale,
#              hcut, hc_method="complete",
#              hc_metric="manhattan",
#              method = "gap", 
#              k.max = 25, verbose = FALSE)
# #K-means
# fviz_nbclust(PLR_Home_Scale,
#              kmeans,
#              method = "wss", 
#              k.max = 25, verbose = FALSE)
# fviz_nbclust(PLR_Home_Scale,
#              kmeans, 
#              method = "silhouette", 
#              k.max = 25, verbose = FALSE)
# fviz_nbclust(PLR_Home_Scale,
#              kmeans,
#              method = "gap", 
#              k.max = 25, verbose = FALSE)
# 
# PLR_kmeans <- kmeans(PLR_Home_Scale, centers=2)
# PLR.kmeans$cluster
```
