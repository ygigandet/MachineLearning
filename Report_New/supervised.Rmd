# Supervised Learning

```{r, echo = FALSE, message = FALSE}
source(here::here("scripts/setup.R"))
```

## Selection of a method of Supervised Learning

```{r}
#### Take the data splitting from Amina ####
# Need to factorise some variables - namely the characters
premier_league_results$home_team = as.factor(premier_league_results$home_team)
premier_league_results$away_team = as.factor(premier_league_results$away_team)
premier_league_results$half_time_results = as.factor(premier_league_results$half_time_results)
premier_league_results$full_time_results = as.factor(premier_league_results$half_time_results)

# Set the seeds to have the same samples over and over
set.seed(234)

train_indexes1 = createDataPartition(premier_league_results$full_time_results,p=0.8,list=FALSE)

train_data1 = premier_league_results[train_indexes1,]  # this is the training set
test_data1 = premier_league_results[-train_indexes1,]  # this is the test set

### End of data splitting from Amina ####
```

### Naive Bayes
```{r}
naivebayesfit <- naive_bayes(premier_league_results$full_time_results ~ ., data=train_data1, usekernel=TRUE)

naivebayespred <- predict(naivebayesfit, newdata = test_data1, type="class")

confusionMatrix(data=as.factor(naivebayespred), reference = test_data1$full_time_results)
```


### K-NN
```{r}
knnfit <- knn3(premier_league_results$full_time_results ~ ., data=train_data1, k=2)

knnpred <- predict(knnfit, newdata = test_data1, type="class")

confusionMatrix(data=as.factor(knnpred), reference = test_data1$full_time_results)
```


### Classification Tree
```{r}
classtreefit <- rpart(premier_league_results$full_time_results ~ ., data=train_data1)

rpart.plot(classtreefit)

plotcp(classtreefit)
classtreefit.pruned <- prune(classtreefit, cp=0.025)

classtreepred <- predict(classtreefit, newdata=test_data1, type="class")

confusionMatrix(data=as.factor(classtreepred), reference = test_data1$full_time_results)
```


### Neural Networks

```{r}
# Now that our sets are ready, let's apply the neural network with caret
set.seed(1)

fitControl <- trainControl(method = "cv", # cv stands for cross-validation 
                           number = 10)

nnetGrid <-  expand.grid(size = seq(from = 1, to = 10, by = 1),
                        decay = seq(from = 0.1, to = 0.5, by = 0.1))

nnetFit <- train(premier_league_results$full_time_results ~ ., 
                 data = train_data1,
                 method = "nnet",
                 metric = "Accuracy",
                 tuneGrid = nnetGrid,
                 trControl = fitControl)

plot(nnetFit)
```

## Supervised Learning Findings

xxx
